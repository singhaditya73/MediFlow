{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5a6621a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing all required packages...\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "✅ All packages installed.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 1: All Installations ---\n",
    "print(\"Installing all required packages...\")\n",
    "%pip install -q fpdf reportlab\n",
    "%pip install -q \"fhir.resources>=7.0.0\"\n",
    "%pip install -q python-dateutil\n",
    "%pip install -q ipywidgets\n",
    "print(\"✅ All packages installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2dee57e8-5fb2-41ae-af0e-26b45f767712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing all libraries...\n",
      "✅ All libraries imported.\n"
     ]
    }
   ],
   "source": [
    "from paddleocr import PaddleOCR # main OCR dependencies\n",
    "from matplotlib import pyplot as plt # plot images\n",
    "import cv2 #opencv\n",
    "import os\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "# --- CELL 2: All Imports ---\n",
    "print(\"Importing all libraries...\")\n",
    "\n",
    "# Core & Data Handling\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import uuid\n",
    "\n",
    "# NLP / Machine Learning\n",
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "# FHIR Resources\n",
    "from fhir.resources.bundle import Bundle, BundleEntry\n",
    "from fhir.resources.patient import Patient\n",
    "from fhir.resources.condition import Condition\n",
    "from fhir.resources.observation import Observation\n",
    "from fhir.resources.medicationrequest import MedicationRequest\n",
    "from fhir.resources.humanname import HumanName\n",
    "from fhir.resources.identifier import Identifier\n",
    "from fhir.resources.codeableconcept import CodeableConcept\n",
    "from fhir.resources.coding import Coding\n",
    "from fhir.resources.quantity import Quantity\n",
    "from fhir.resources.reference import Reference\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, FileLink\n",
    "\n",
    "print(\"✅ All libraries imported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23f32531-ef07-4642-8c01-1595e3e387cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CELL 3: Defining OCR and Data Extraction Functions ---\n",
      "✅ CELL 3 Complete: OCR and Extraction functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 3: OCR & Data Extraction System (V3) ---\n",
    "print(\"\\n--- CELL 3: Defining OCR and Data Extraction Functions ---\")\n",
    "\n",
    "# --- OCR Setup ---\n",
    "if 'paddle_ocr' not in globals():\n",
    "    paddle_ocr = PaddleOCR(lang='en', use_angle_cls=True)\n",
    "    print(\"✅ PaddleOCR model loaded.\")\n",
    "\n",
    "def run_medical_ocr(image_path):\n",
    "    \"\"\"Run PaddleOCR on an image and return recognized text.\"\"\"\n",
    "    try:\n",
    "        # --- FIX IS HERE ---\n",
    "        # The 'cls' argument is no longer supported in this call.\n",
    "        result = paddle_ocr.predict(image_path)\n",
    "        # --- END FIX ---\n",
    "        \n",
    "        lines = result[0]\n",
    "        texts = [line[1][0] for line in lines]\n",
    "        return \"\\n\".join(texts)\n",
    "    except Exception as e:\n",
    "        print(f\"❌ PaddleOCR failed: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# --- NER Setup ---\n",
    "if 'ner_pipeline' not in globals():\n",
    "    # Use device=0 for GPU if available, otherwise device=-1 for CPU\n",
    "    device = 0 if torch.cuda.is_available() else -1\n",
    "    ner_pipeline = pipeline(\"ner\", model=\"d4data/biomedical-ner-all\", tokenizer=\"d4data/biomedical-ner-all\", device=device, grouped_entities=True)\n",
    "    print(f\"✅ BioBERT NER model loaded on device: {'GPU' if device == 0 else 'CPU'}.\")\n",
    "\n",
    "# --- Extraction Helper Functions ---\n",
    "def safe_search(pattern, text, group=1):\n",
    "    \"\"\"Safely perform regex search.\"\"\"\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    return match.group(group).strip() if match else None\n",
    "\n",
    "def extract_section(text, start_keywords, end_keywords):\n",
    "    \"\"\"Extract a section between start and end keywords.\"\"\"\n",
    "    start_pattern = '|'.join([re.escape(k) for k in start_keywords])\n",
    "    end_pattern = '|'.join([re.escape(k) for k in end_keywords])\n",
    "    pattern = rf'(?:{start_pattern})[\\s:]*(.*?)(?=\\n(?:{end_pattern})|$)'\n",
    "    match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)\n",
    "    return match.group(1).strip() if match else None\n",
    "\n",
    "# --- Main Extraction Logic ---\n",
    "def extract_medical_data(report_text, ner_pipeline):\n",
    "    \"\"\"Main function to detect document type and extract data accordingly.\"\"\"\n",
    "    # Simple document type detection\n",
    "    if re.search(r\"COVID-19|PCR|MOLECULAR\\s+DIAGNOSTIC\", report_text, re.IGNORECASE):\n",
    "        doc_type = \"lab_report\"\n",
    "    elif re.search(r\"DISCHARGE\\s+SUMMARY\", report_text, re.IGNORECASE):\n",
    "        doc_type = \"discharge_summary\"\n",
    "    else:\n",
    "        doc_type = \"clinical_report\"\n",
    "    \n",
    "    print(f\"Detected document type: {doc_type}\")\n",
    "\n",
    "    # For this consolidated example, we will use a generic extractor.\n",
    "    print(\"Processing with generic clinical report extractor...\")\n",
    "    extracted = {\n",
    "        \"document_type\": doc_type, \"patient_info\": {}, \"report_meta\": {},\n",
    "        \"conditions\": [], \"medications\": [], \"vitals\": [],\n",
    "    }\n",
    "\n",
    "    # Patient Info\n",
    "    extracted[\"patient_info\"]['name'] = safe_search(r\"(?:Patient|Name)\\s*:\\s*([A-Za-z\\s.-]+)\", report_text)\n",
    "    extracted[\"patient_info\"]['id'] = safe_search(r\"(?:MRN|Patient ID)\\s*:\\s*([A-Za-z0-9-]+)\", report_text)\n",
    "    extracted[\"patient_info\"]['gender'] = safe_search(r\"(?:Sex|Gender)\\s*:\\s*(Male|Female|M|F)\", report_text)\n",
    "    extracted[\"patient_info\"]['dob'] = safe_search(r\"(?:DOB|Date of Birth)\\s*:\\s*(\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4})\", report_text)\n",
    "\n",
    "    # Vitals\n",
    "    vital_patterns = {\n",
    "        'BP': r\"BP\\s*[:=]\\s*(\\d+/\\d+)\", 'HR': r\"HR\\s*[:=]\\s*(\\d+)\",\n",
    "        'RR': r\"RR\\s*[:=]\\s*(\\d+)\", 'TEMP': r\"T\\s*[:=]\\s*([0-9.,]+)\",\n",
    "    }\n",
    "    for vital, pattern in vital_patterns.items():\n",
    "        value = safe_search(pattern, report_text)\n",
    "        if value:\n",
    "            extracted[\"vitals\"].append({\"name\": vital, \"value\": value})\n",
    "    \n",
    "    # NER for Conditions and Medications\n",
    "    try:\n",
    "        ner_results = ner_pipeline(report_text[:4000]) # Limit text for performance\n",
    "        for entity in ner_results:\n",
    "            entity_group = entity['entity_group']\n",
    "            entity_text = entity['word']\n",
    "            \n",
    "            if entity['score'] > 0.8: # Confidence threshold\n",
    "                if entity_group in [\"DISEASE\", \"PROBLEM\"] and entity_text not in extracted[\"conditions\"]:\n",
    "                    extracted[\"conditions\"].append(entity_text)\n",
    "                elif entity_group in [\"DRUG\", \"CHEMICAL\"] and entity_text not in extracted[\"medications\"]:\n",
    "                    extracted[\"medications\"].append(entity_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during NER processing: {e}\")\n",
    "\n",
    "    return extracted\n",
    "\n",
    "print(\"✅ CELL 3 Complete: OCR and Extraction functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a522f96-ecff-4c25-a368-53df488d80ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CELL 4: Defining Custom-to-FHIR Transformer ---\n",
      "✅ CELL 4 Complete: FHIR Transformer functions defined.\n"
     ]
    }
   ],
   "source": [
    "# --- CELL 4: Custom-to-FHIR Transformer ---\n",
    "print(\"\\n--- CELL 4: Defining Custom-to-FHIR Transformer ---\")\n",
    "\n",
    "def safe_parse_date(date_string):\n",
    "    \"\"\"Safely parse various date formats into FHIR-compatible ISO format.\"\"\"\n",
    "    if not date_string: return None\n",
    "    try:\n",
    "        return parse(date_string.replace(\"/\", \"-\"), yearfirst=False, dayfirst=True).date().isoformat()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def create_patient_resource(patient_info):\n",
    "    \"\"\"Converts patient_info dict to a FHIR Patient resource.\"\"\"\n",
    "    patient = Patient()\n",
    "    patient.id = str(uuid.uuid4())\n",
    "    if patient_info.get('name'):\n",
    "        name = HumanName(text=patient_info['name'])\n",
    "        patient.name = [name]\n",
    "    if patient_info.get('gender'):\n",
    "        patient.gender = patient_info['gender'].lower().strip()[0] == 'm' and 'male' or 'female'\n",
    "    if patient_info.get('dob'):\n",
    "        patient.birthDate = safe_parse_date(patient_info.get('dob'))\n",
    "    if patient_info.get('id'):\n",
    "        patient.identifier = [Identifier(system=\"http://hospital.example/mrn\", value=patient_info['id'])]\n",
    "    return patient\n",
    "\n",
    "def create_condition_resources(diagnoses, patient_ref):\n",
    "    \"\"\"Converts a list of diagnoses to FHIR Condition resources.\"\"\"\n",
    "    return [Condition(\n",
    "        id=str(uuid.uuid4()),\n",
    "        subject=patient_ref,\n",
    "        clinicalStatus=CodeableConcept(coding=[Coding(system=\"http://terminology.hl7.org/CodeSystem/condition-clinical\", code=\"active\")]),\n",
    "        code=CodeableConcept(text=diag_text)\n",
    "    ) for diag_text in diagnoses]\n",
    "\n",
    "def create_observation_resources(vitals, patient_ref):\n",
    "    \"\"\"Converts vitals list to FHIR Observation resources.\"\"\"\n",
    "    resources = []\n",
    "    loinc_map = {'BP': '85354-9', 'HR': '8867-4', 'RR': '9279-1', 'TEMP': '8310-5'}\n",
    "    for vital in vitals:\n",
    "        if vital.get('name') not in loinc_map: continue\n",
    "        obs = Observation(\n",
    "            id=str(uuid.uuid4()), status=\"final\", subject=patient_ref,\n",
    "            category=[CodeableConcept(coding=[Coding(system=\"http://terminology.hl7.org/CodeSystem/observation-category\", code=\"vital-signs\")])],\n",
    "            code=CodeableConcept(coding=[Coding(system=\"http://loinc.org\", code=loinc_map[vital['name']])], text=vital['name'])\n",
    "        )\n",
    "        if vital['name'] == 'BP':\n",
    "            parts = vital['value'].split('/')\n",
    "            if len(parts) == 2:\n",
    "                obs.component = [\n",
    "                    Observation.Component(code=CodeableConcept(coding=[Coding(system=\"http://loinc.org\", code=\"8480-6\")]), valueQuantity=Quantity(value=float(parts[0]), unit=\"mmHg\")),\n",
    "                    Observation.Component(code=CodeableConcept(coding=[Coding(system=\"http://loinc.org\", code=\"8462-4\")]), valueQuantity=Quantity(value=float(parts[1]), unit=\"mmHg\"))\n",
    "                ]\n",
    "        else:\n",
    "            numeric_val = re.search(r'([0-9.,]+)', vital['value'])\n",
    "            if numeric_val:\n",
    "                obs.valueQuantity = Quantity(value=float(numeric_val.group(1).replace(',','.')), unit = 'C' if vital['name'] == 'TEMP' else '/min')\n",
    "        if obs.component or obs.valueQuantity:\n",
    "            resources.append(obs)\n",
    "    return resources\n",
    "    \n",
    "def create_medication_resources(medications, patient_ref):\n",
    "    \"\"\"Converts medication list to FHIR MedicationRequest resources.\"\"\"\n",
    "    return [MedicationRequest(\n",
    "        id=str(uuid.uuid4()), status=\"active\", intent=\"order\", subject=patient_ref,\n",
    "        medicationCodeableConcept=CodeableConcept(text=med_text)\n",
    "    ) for med_text in medications]\n",
    "\n",
    "def convert_custom_to_fhir(custom_data):\n",
    "    \"\"\"Main function to convert the custom dictionary into a FHIR Bundle.\"\"\"\n",
    "    if not custom_data or not custom_data.get('patient_info'):\n",
    "        print(\"❌ FHIR Conversion Failed: No patient information found.\")\n",
    "        return None\n",
    "        \n",
    "    bundle = Bundle(type=\"collection\", id=str(uuid.uuid4()), entry=[])\n",
    "    \n",
    "    patient = create_patient_resource(custom_data['patient_info'])\n",
    "    patient_ref = Reference(reference=f\"Patient/{patient.id}\")\n",
    "    bundle.entry.append(Bundle.Entry(resource=patient, fullUrl=f\"urn:uuid:{patient.id}\"))\n",
    "\n",
    "    resources = [\n",
    "        *create_condition_resources(custom_data.get('conditions', []), patient_ref),\n",
    "        *create_observation_resources(custom_data.get('vitals', []), patient_ref),\n",
    "        *create_medication_resources(custom_data.get('medications', []), patient_ref)\n",
    "    ]\n",
    "    for res in resources:\n",
    "        bundle.entry.append(Bundle.Entry(resource=res, fullUrl=f\"urn:uuid:{res.id}\"))\n",
    "        \n",
    "    print(f\"✅ FHIR Bundle created with {len(bundle.entry)} resources.\")\n",
    "    return bundle\n",
    "\n",
    "print(\"✅ CELL 4 Complete: FHIR Transformer functions defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a973952-5007-45e1-be5f-bcc876ee8032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- CELL 5: Initializing Simplified UI Pipeline ---\n",
      "✅ Ready to process.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cea45fe743654440b5ea4f1175fe72b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value=(), accept='.pdf,.png,.jpg,.jpeg', description='Upload Report'), Button(button…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- CELL 5: Single-Button Interactive Pipeline ---\n",
    "print(\"\\n--- CELL 5: Initializing Simplified UI Pipeline ---\")\n",
    "\n",
    "# We need FPDF for PDF generation\n",
    "from fpdf import FPDF\n",
    "from datetime import datetime\n",
    "from IPython.display import FileLink, clear_output\n",
    "import ipywidgets as widgets\n",
    "import json\n",
    "\n",
    "# --- 1. Helper Function to Generate a PDF Report ---\n",
    "def create_medical_report_pdf(data, pdf_path):\n",
    "    \"\"\"Generates a human-readable PDF summary from the extracted data.\"\"\"\n",
    "    pdf = FPDF()\n",
    "    pdf.add_page()\n",
    "    pdf.set_font(\"Arial\", size=10)\n",
    "\n",
    "    # Helper to add a titled section\n",
    "    def add_section(title, content_dict):\n",
    "        pdf.set_font(\"Arial\", 'B', 14)\n",
    "        pdf.cell(0, 10, title, 0, 1, 'L')\n",
    "        pdf.set_font(\"Arial\", size=10)\n",
    "        if not content_dict:\n",
    "            pdf.cell(0, 7, \"  - No data found -\", 0, 1)\n",
    "            return\n",
    "        for key, value in content_dict.items():\n",
    "            line = f\"  {str(key).replace('_', ' ').title()}: {str(value)}\"\n",
    "            try:\n",
    "                pdf.cell(0, 7, line, 0, 1)\n",
    "            except UnicodeEncodeError:\n",
    "                pdf.cell(0, 7, line.encode('latin-1', 'replace').decode('latin-1'), 0, 1)\n",
    "        pdf.ln(5)\n",
    "\n",
    "    # Helper for lists\n",
    "    def add_list_section(title, content_list):\n",
    "        pdf.set_font(\"Arial\", 'B', 14)\n",
    "        pdf.cell(0, 10, title, 0, 1, 'L')\n",
    "        pdf.set_font(\"Arial\", size=10)\n",
    "        if not content_list:\n",
    "            pdf.cell(0, 7, \"  - No data found -\", 0, 1)\n",
    "            return\n",
    "        for item in content_list:\n",
    "            line = f\"  - {str(item)}\"\n",
    "            try:\n",
    "                pdf.multi_cell(0, 7, line)\n",
    "            except UnicodeEncodeError:\n",
    "                pdf.multi_cell(0, 7, line.encode('latin-1', 'replace').decode('latin-1'))\n",
    "        pdf.ln(5)\n",
    "\n",
    "    # --- Build the PDF ---\n",
    "    pdf.set_font(\"Arial\", 'B', 16)\n",
    "    pdf.cell(0, 10, \"Medical Report Summary\", 0, 1, 'C')\n",
    "    pdf.ln(10)\n",
    "\n",
    "    add_section(\"Patient Information\", data.get(\"patient_info\"))\n",
    "    add_list_section(\"Vitals\", [f\"{v['name']}: {v['value']}\" for v in data.get(\"vitals\", [])])\n",
    "    add_list_section(\"Conditions / Diagnoses\", data.get(\"conditions\"))\n",
    "    add_list_section(\"Medications\", data.get(\"medications\"))\n",
    "    \n",
    "    pdf.output(pdf_path)\n",
    "\n",
    "# --- 2. Define the UI Widgets ---\n",
    "output_area = widgets.Output()\n",
    "upload_widget = widgets.FileUpload(\n",
    "    accept=\".pdf,.png,.jpg,.jpeg\",\n",
    "    multiple=False,\n",
    "    description=\"Upload Report\"\n",
    ")\n",
    "process_btn = widgets.Button(\n",
    "    description=\"Process Uploaded File\",\n",
    "    button_style='success',\n",
    "    tooltip='Run the full OCR and FHIR pipeline'\n",
    ")\n",
    "\n",
    "# --- 3. Define the Main Callback Function ---\n",
    "def process_uploaded_file(btn):\n",
    "    \"\"\"The main function triggered by the 'Process' button.\"\"\"\n",
    "    with output_area:\n",
    "        clear_output(wait=True)\n",
    "        \n",
    "        if not upload_widget.value:\n",
    "            print(\"⚠️ Please upload a file first.\")\n",
    "            return\n",
    "            \n",
    "        # --- File Handling ---\n",
    "        uploaded_file_dict = upload_widget.value[0]\n",
    "        temp_file_path = Path(f\"temp_{uploaded_file_dict['name']}\")\n",
    "        with open(temp_file_path, \"wb\") as f:\n",
    "            f.write(uploaded_file_dict['content'])\n",
    "        print(f\"✅ File saved locally: {temp_file_path}\")\n",
    "\n",
    "        base_name = f\"{temp_file_path.stem}_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "        try:\n",
    "            # --- Step 1: Run OCR (from Cell 3) ---\n",
    "            print(\"🔹 Running PaddleOCR...\")\n",
    "            ocr_text = run_medical_ocr(str(temp_file_path))\n",
    "            if not ocr_text:\n",
    "                print(\"❌ OCR Failed. Cannot continue.\")\n",
    "                return\n",
    "            print(\"✅ OCR Completed.\")\n",
    "\n",
    "            # --- Step 2: Run Extraction (from Cell 3) ---\n",
    "            print(\"🔹 Extracting medical entities...\")\n",
    "            custom_data = extract_medical_data(ocr_text, ner_pipeline)\n",
    "            print(\"✅ Custom data extracted.\")\n",
    "\n",
    "            # --- Step 3: Run FHIR Conversion (from Cell 4) ---\n",
    "            print(\"🔹 Converting to FHIR Bundle...\")\n",
    "            fhir_bundle = convert_custom_to_fhir(custom_data)\n",
    "            print(\"✅ FHIR conversion complete.\")\n",
    "\n",
    "            # --- Step 4: Save all files ---\n",
    "            custom_json_path = f\"{base_name}_custom.json\"\n",
    "            with open(custom_json_path, \"w\") as f:\n",
    "                json.dump(custom_data, f, indent=2)\n",
    "            print(f\"📄 Custom JSON saved: {custom_json_path}\")\n",
    "\n",
    "            if fhir_bundle:\n",
    "                fhir_json_path = f\"{base_name}_fhir.json\"\n",
    "                with open(fhir_json_path, \"w\") as f:\n",
    "                    f.write(fhir_bundle.json(indent=2))\n",
    "                print(f\"📄 FHIR Bundle saved: {fhir_json_path}\")\n",
    "            \n",
    "            pdf_path = f\"{base_name}_report.pdf\"\n",
    "            create_medical_report_pdf(custom_data, pdf_path)\n",
    "            print(f\"📄 PDF Report generated: {pdf_path}\")\n",
    "\n",
    "            # --- Step 5: Display download links ---\n",
    "            print(\"\\n--- Download Your Files ---\")\n",
    "            display(FileLink(custom_json_path))\n",
    "            if fhir_bundle:\n",
    "                display(FileLink(fhir_json_path))\n",
    "            display(FileLink(pdf_path))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌❌❌ An error occurred during processing: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            # Clean up the temporary file\n",
    "            temp_file_path.unlink()\n",
    "            \n",
    "            # --- FIX IS HERE ---\n",
    "            # Set value to an empty tuple () to clear the widget\n",
    "            upload_widget.value = ()\n",
    "            # --- END FIX ---\n",
    "            \n",
    "            upload_widget._counter = 0\n",
    "\n",
    "# --- 4. Link Callback and Display UI ---\n",
    "process_btn.on_click(process_uploaded_file)\n",
    "\n",
    "ui = widgets.VBox([upload_widget, process_btn, output_area])\n",
    "print(\"✅ Ready to process.\")\n",
    "display(ui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "913d902b-dbd6-4d68-ba91-11e10824aa68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q reportlab pdf2image pillow ipywidgets python-dateutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f98f990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fpdf\n",
      "  Downloading fpdf-1.7.2.tar.gz (39 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: fpdf\n",
      "\u001b[33m  DEPRECATION: Building 'fpdf' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'fpdf'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for fpdf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for fpdf: filename=fpdf-1.7.2-py2.py3-none-any.whl size=40758 sha256=9c8284cd405ebb77505f861c3390368e6b7a436ed2003dd47b3f69975eb82bd6\n",
      "  Stored in directory: /home/aditya73/.cache/pip/wheels/f9/95/ba/f418094659025eb9611f17cbcaf2334236bf39a0c3453ea455\n",
      "Successfully built fpdf\n",
      "Installing collected packages: fpdf\n",
      "Successfully installed fpdf-1.7.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install fpdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9148336-67a9-44fc-a131-cc1e633897c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bb5f8360bbf4d3baff84ebfa0b3a3eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d73c0ba4cea480d8b009dd24b9a0d40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf,.png,.jpg,.jpeg,.webp', description='Upload')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101dd01b08bc4fc692f8af96137086af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='success', description='Process Uploaded File', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "page_result = result[0]\n",
    "\n",
    "# Extract recognized text\n",
    "texts = page_result['rec_texts']\n",
    "scores = page_result['rec_scores']\n",
    "\n",
    "# Print text with confidence\n",
    "for text, score in zip(texts, scores):\n",
    "    print(f\"{text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a01e6d-ac43-4b06-8885-3fd9b018e8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b065dea0-e001-4aed-b741-008d2c9b3166",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paddle-ocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
